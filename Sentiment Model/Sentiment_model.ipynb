{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/1.28M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.28M/1.28M [00:00<00:00, 6.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494k/494k [00:00<00:00, 2.72MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.tsv.zip to .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494k/494k [00:00<00:00, 2.72MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "for file in ['train.tsv', 'test.tsv']:\n",
    "    api.competition_download_file('sentiment-analysis-on-movie-reviews', f'{file}.zip', path='./')\n",
    "\n",
    "    with zipfile.ZipFile(f'{file}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "\n",
    "    os.remove(f'{file}.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('train.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = ['SentenceId'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId                                             Phrase  \\\n",
       "0           1           1  A series of escapades demonstrating the adage ...   \n",
       "63         64           2  This quiet , introspective and entertaining in...   \n",
       "81         82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "116       117           4  A positively thrilling combination of ethnogra...   \n",
       "156       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 512)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 4)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokens = tokenizer(df['Phrase'].tolist(),max_length= seq_len, truncation= True, padding = 'max_length', add_special_tokens = True, return_tensors = 'np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy arrays\n",
    "\n",
    "with open('movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "with open('movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y variable\n",
    "\n",
    "arr = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    " # onehot encoding\n",
    "    \n",
    "labels = np.zeros((num_samples, arr.max()+ 1))\n",
    "\n",
    "# index arr to 1\n",
    "\n",
    "labels[np.arange(num_samples), arr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids = tokens['input_ids']\n",
    "Xmask = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids,Xmask,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to kwargs\n",
    "\n",
    "def map_func(input_ids,masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_masks': masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = dataset.shuffle(100).batch(batch_size, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test skip skips the first 8000, val takes the rest\n",
    "\n",
    "train_ds = dataset.take(900)\n",
    "val_ds = dataset.skip(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "tf.data.experimental.save(train_ds,'train')\n",
    "tf.data.experimental.save(val_ds,'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#define inputs\n",
    "input_ids = tf.keras.layers.Input(shape = (512,), name = 'input_ids', dtype = 'int32')\n",
    "mask =tf.keras.layers.Input(shape = (512,), name = 'attention_masks', dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer\n",
    "\n",
    "# bert.bert returns two activations -> 0 = raw 1 = max pooled\n",
    "embeddings = bert.bert(input_ids, attention_mask =mask)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier head\n",
    "\n",
    "x = tf.keras.layers.Dense(1024,activation = 'relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation = 'softmax', name = 'outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = [input_ids, mask],outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze bert layer\n",
    "\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer =  tf.keras.optimizers.Adam(lr = 5e-5, decay = 1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform' defined at (most recent call last):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n      self.run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-243-bfe82f7e859e>\", line 1, in <module>\n      history = model.fit(train_ds,\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 655, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 429, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 433, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 399, in call\n      attention_outputs = self.attention(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 343, in call\n      self_outputs = self.self_attention(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 298, in call\n      attention_probs = self.dropout(attention_probs, training=training)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\core\\dropout.py\", line 111, in call\n      output = control_flow_util.smart_cond(training, dropped_inputs,\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\core\\dropout.py\", line 108, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 1940, in dropout\n      return tf.nn.dropout(inputs, rate=rate, noise_shape=noise_shape,\nNode: 'model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform'\nOOM when allocating tensor with shape[8,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_176146]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-bfe82f7e859e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_ds, \n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     epochs = 5)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform' defined at (most recent call last):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n      self.run()\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-243-bfe82f7e859e>\", line 1, in <module>\n      history = model.fit(train_ds,\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 655, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 429, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 433, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 399, in call\n      attention_outputs = self.attention(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 343, in call\n      self_outputs = self.self_attention(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 298, in call\n      attention_probs = self.dropout(attention_probs, training=training)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\core\\dropout.py\", line 111, in call\n      output = control_flow_util.smart_cond(training, dropped_inputs,\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\core\\dropout.py\", line 108, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"C:\\Users\\91760\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\backend.py\", line 1940, in dropout\n      return tf.nn.dropout(inputs, rate=rate, noise_shape=noise_shape,\nNode: 'model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform'\nOOM when allocating tensor with shape[8,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_7/bert/encoder/layer_._2/attention/self/dropout_229/dropout/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_176146]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    validation_data = val_ds,\n",
    "                    epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
